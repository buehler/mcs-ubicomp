{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7420f93f",
   "metadata": {},
   "source": [
    "# (Pseudo-) Online Feature Calculation\n",
    "\n",
    "This notebook is used to receive data from the HoloLens 2. The data is chunked in 10 second pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a494ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc384884",
   "metadata": {},
   "source": [
    "## Read the data from the newly arrived csv-file and call the feature calculation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "350e695e",
   "metadata": {},
   "source": [
    "### Run FeaturesCalculation notebook to make its function accessible here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i FeatureCalculation.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25237aa8",
   "metadata": {},
   "source": [
    "## Calculate the features and save them as csv\n",
    "See `FeaturesCalculation.ipynb`for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features_for_10s_chunk(newdf):\n",
    "    list_of_features = []\n",
    "    newdf_valid = only_valid_data(newdf)\n",
    "    if (len(newdf_valid) > 1):\n",
    "        df_fixations = get_fixation_df(newdf_valid)\n",
    "        features = calculate_fixation_features(df_fixations, 10)\n",
    "        blinks = calculate_blink_features(newdf,10)\n",
    "        directions = calculate_directions_of_list(df_fixations) \n",
    "        density = calculate_fixation_density(newdf_valid, df_fixations)\n",
    "        features.update(blinks)\n",
    "        features.update(directions)\n",
    "        features.update(density)\n",
    "        features[\"label\"] = \"\"\n",
    "        features[\"duration\"] = \"10\"\n",
    "        features[\"participant_id\"] = \"002\"            \n",
    "        list_of_features.append(features)  \n",
    "        flat_ls = [item for sublist in list_of_features for item in sublist]\n",
    "        feature_file_path = save_as_csv(list_of_features, \"001\", './OnlineFeatureFiles/')\n",
    "        return feature_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_features(gaze_data_file_path):\n",
    "    # continue only if the csv-file contains data\n",
    "    if os.stat(gaze_data_file_path).st_size != 0:\n",
    "        df = pd.read_csv(gaze_data_file_path)\n",
    "        feature_file_path = calculate_features_for_10s_chunk(df)\n",
    "        print(f\"Feature calculation done for: {gaze_data_file_path}\")\n",
    "        print(f\"Feature file path: {feature_file_path}\")\n",
    "        return feature_file_path\n",
    "    else:\n",
    "        print(f\"File {gaze_data_file_path} is empty!\")\n",
    "        return \"\"\n",
    "# csv_to_features(\"./HL2_DataCollection/2022_09_23-13_41_19-Alex01-Inspection02.csv\")\n",
    "# uncomment the line above to test the function with a local csv file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01e6fc90",
   "metadata": {},
   "source": [
    "## Run SVM notebook to make its function accessible here\n",
    "If you are not training on normalized data this make take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528de9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i AnSVMClassifierForHL2GazeFeatures.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9682dbc1",
   "metadata": {},
   "source": [
    "## Predict the class for the last arrived data chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_values(df): \n",
    "    scaler = MaxAbsScaler()\n",
    "    training_features_plus_new_row = pd.concat([features, df])  # features -> contains all the features for training and testing\n",
    "    scaler.fit(training_features_plus_new_row)\n",
    "    scaled = scaler.transform(training_features_plus_new_row)\n",
    "    scaled_features = pd.DataFrame(scaled, columns=df.columns)\n",
    "    row_for_last_chunk = scaled_features.tail(1)\n",
    "    print(\"Normalized Features:\")\n",
    "    display(row_for_last_chunk)\n",
    "    return row_for_last_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_counter = 0\n",
    "classes = [\"Inspection\", \"Reading\", \"Search\"]\n",
    "kernels = [linear, poly, rbf, sig]\n",
    "def predict_class_for_last_chunk(feature_file_path):\n",
    "    if os.stat(feature_file_path).st_size != 0:\n",
    "        df = pd.read_csv(feature_file_path)\n",
    "        cur_number_of_rows = df.shape[0]\n",
    "        # only continue if we have a new row\n",
    "        if cur_number_of_rows > row_counter:\n",
    "            last_row = df.tail(1)\n",
    "            display(last_row)\n",
    "            \n",
    "            lr_features= last_row[[\"meanFix\", \"maxFix\", \"varFix\", \"xDir\", \"yDir\", \"fixDensPerBB\"]]\n",
    "            last_row = normalize_values(lr_features)\n",
    "            \n",
    "            classes = linear.classes_\n",
    "            # print(f\"\\n---\\nclasses: {classes}\")\n",
    "            \n",
    "            results = {}\n",
    "            \n",
    "            for kernel in kernels:\n",
    "                new_pred_prob = kernel.predict_proba(last_row)\n",
    "                new_pred_class = kernel.predict(last_row)\n",
    "                # print(\"\\n---\\nNew Prediction:\")\n",
    "                display(new_pred_prob)\n",
    "                display(new_pred_class)\n",
    "                pred_list = new_pred_prob.tolist()[0]\n",
    "                max_prob = max(pred_list)\n",
    "                # print(f\"max_prob: {max_prob}\")\n",
    "                max_index = pred_list.index(max_prob)\n",
    "                # print(f\"max_index: {max_prob}\")\n",
    "                results[kernel.kernel] = {\"pred_class\": new_pred_class[0], \"max_prob\": max_prob, \"max_index\": max_index }\n",
    "                # results[kernel.kernel] = [new_pred_class[0], max_prob, max_index ]\n",
    "                \n",
    "            display(results)\n",
    "        \n",
    "            \n",
    "            max_proba = {max(float(d['max_prob']) for d in results.values())}\n",
    "            key = [i for i in results if results[i]['max_prob']==max_proba]\n",
    "            # print(f\"max_proba: {max_proba}, key: {key}\")\n",
    "            predicts = [d['pred_class'] for d in results.values()]\n",
    "            final_class_from_predict = max(set(predicts), key = predicts.count)\n",
    "            # print(f\"final_class_from_predict: {final_class_from_predict}\")\n",
    "            \n",
    "            \n",
    "            new_linear_pred_prob = linear.predict_proba(last_row)\n",
    "            new_linear_pred_class = linear.predict(last_row)\n",
    "            # print(\"\\n---\\nNew Linear Prediction:\")\n",
    "            # display(new_linear_pred_prob)\n",
    "            # display(new_linear_pred_class)\n",
    "            lin_list = new_linear_pred_prob.tolist()[0]\n",
    "            lin_max_prob = max(lin_list)\n",
    "            # print(f\"lin_max_prob: {lin_max_prob}\")\n",
    "            lin_max_index = lin_list.index(lin_max_prob)\n",
    "            # print(f\"lin_max_index: {lin_max_index}\")\n",
    "\n",
    "            new_poly_pred_prob = poly.predict_proba(last_row)\n",
    "            new_poly_pred_class = poly.predict(last_row)\n",
    "            # print(\"\\n---\\nNew Poly Prediction:\")\n",
    "            # display(new_poly_pred_prob)\n",
    "            # display(new_poly_pred_class)\n",
    "            poly_list = new_poly_pred_prob.tolist()[0]\n",
    "            poly_max_prob = max(poly_list)\n",
    "            # print(f\"poly_max_prob: {poly_max_prob}\")\n",
    "            poly_max_index = poly_list.index(poly_max_prob)\n",
    "            # print(f\"poly_max_index: {poly_max_index}\")\n",
    "\n",
    "            new_rbf_pred_prob = rbf.predict_proba(last_row)\n",
    "            new_rbf_pred_class = rbf.predict(last_row)\n",
    "            # print(\"\\n---\\nNew RBF Prediction:\")\n",
    "            # display(new_rbf_pred_prob)\n",
    "            # display(new_rbf_pred_class)\n",
    "            rbf_list = new_rbf_pred_prob.tolist()[0]\n",
    "            rbf_max_prob = max(rbf_list)\n",
    "            # print(f\"rbf_max_prob: {rbf_max_prob}\")\n",
    "            rbf_max_index = rbf_list.index(rbf_max_prob)\n",
    "            # print(f\"rbf_max_index: {rbf_max_index}\")\n",
    "            \n",
    "\n",
    "            new_sig_pred_prob = sig.predict_proba(last_row)\n",
    "            new_sig_pred_class = sig.predict(last_row)\n",
    "            # print(\"\\n---\\nNew Sig Prediction:\")\n",
    "            # display(new_sig_pred_prob)\n",
    "            # display(new_sig_pred_class)\n",
    "            sig_list = new_sig_pred_prob.tolist()[0]\n",
    "            sig_max_prob = max(sig_list)\n",
    "            # print(f\"sig_max_prob: {sig_max_prob}\")\n",
    "            sig_max_index = sig_list.index(sig_max_prob)\n",
    "            # print(f\"sig_max_index: {sig_max_index}\")\n",
    "            \n",
    "            print(\"----------------\")\n",
    "            max_probs = { lin_max_prob: lin_max_index, poly_max_prob: poly_max_index,\n",
    "                        rbf_max_prob: rbf_max_index}\n",
    "            \n",
    "            max_prediction_value = max(max_probs, key=float)\n",
    "            # print(max_prediction_value)\n",
    "            final_max_index = max_probs[max_prediction_value]\n",
    "            final_class_from_probs = classes[final_max_index]\n",
    "            \n",
    "            # print(f\"final_class_from_probs: {final_class_from_probs}\")\n",
    "            \n",
    "            predicts = [new_linear_pred_class[0], new_poly_pred_class[0], new_rbf_pred_class[0]]\n",
    "            final_class_from_predict = max(set(predicts), key = predicts.count)\n",
    "            # print(f\"final_class_from_predict: {final_class_from_predict}\")\n",
    "            \n",
    "            \n",
    "            same_class_predicted = (final_class_from_probs == final_class_from_predict)\n",
    "            # print(f\"same_class_predicted: {same_class_predicted}\")\n",
    "            \n",
    "            if (same_class_predicted and max_prediction_value > 0.5):\n",
    "                # send request to HL2 with class and probability\n",
    "                send_activity(final_class_from_probs, max_prediction_value)\n",
    "            \n",
    "# predict_class_for_last_chunk(\"FeatureFiles/feature_list_P09.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7abd846c",
   "metadata": {},
   "source": [
    "## Send the recognized activity back to the HoloLens 2 \n",
    "\n",
    "⚠️ Make sure to set the correct IP address for the HL2!\n",
    "\n",
    "If you run the app via Holographic remoting, this is your PC's IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import requests\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Remember to change the IP address and port if needed!\n",
    "# Start the HL2 app first, an input the url and port that you see in MR here\n",
    "holo_url = \"http://10.2.2.152:52739\"\n",
    "\n",
    "def send_activity(activity, probability):\n",
    "\n",
    "    url = \"{}/?activity={}&probability={}\".format(str(holo_url), str(activity), str(probability))\n",
    "    print(url)\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, timeout=120)\n",
    "        print(r)\n",
    "        if r.status_code == 200:\n",
    "            print(\"Notified Hololens about activity {}\".format(activity))\n",
    "        else:\n",
    "            print(\"Request {} failed with status code {}\".format(url, r.status_code))\n",
    "    except requests.ConnectionError as e:\n",
    "        print(\"OOPS!! Connection Error. Make sure you are connected to Internet. Technical Details given below.\\n\")\n",
    "        print(str(e))\n",
    "    except requests.Timeout as e:\n",
    "        print(\"OOPS!! Timeout Error\")\n",
    "        print(str(e))\n",
    "    except requests.RequestException as e:\n",
    "        print(\"OOPS!! General Error\")\n",
    "        print(str(e))\n",
    "\n",
    "    else:\n",
    "        return\n",
    "\n",
    "def create_and_send_test_data():\n",
    "    activities = [\"reading\", \"writing\", \"searching\", \"inspecting\"]\n",
    "    a = random.randint(0, 3)\n",
    "    activity = activities[a]\n",
    "    confidence = random.uniform(0, 1)\n",
    "    print(f\"{activity}: {confidence}\")\n",
    "    send_activity(activity, confidence)\n",
    "\n",
    "\n",
    "def sender():\n",
    "    start_time = time.time()\n",
    "    interval = 5\n",
    "    for i in range(20):\n",
    "        time.sleep(start_time + i * interval - time.time())\n",
    "        create_and_send_test_data()\n",
    "        print(\"sent data\")\n",
    "\n",
    "def send_this_desktop_ip_to_holo(desktop_ip, port):\n",
    "    \n",
    "    desktop_ip = urllib.parse.quote(desktop_ip)\n",
    "\n",
    "    url = \"{}/?desktopip={}&port={}\".format(str(holo_url), str(desktop_ip), str(port))\n",
    "    print(url)\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, timeout=60)\n",
    "        print(r)\n",
    "        if r.status_code == 200:\n",
    "            print(\"Notified Hololens about IP address {}\".format(desktop_ip))\n",
    "        else:\n",
    "            print(\"Request {} failed with status code {}\".format(url, r.status_code))\n",
    "    except requests.ConnectionError as e:\n",
    "        print(\"OOPS!! Connection Error. Make sure you are connected to Internet. Technical Details given below.\\n\")\n",
    "        print(str(e))\n",
    "    except requests.Timeout as e:\n",
    "        print(\"OOPS!! Timeout Error\")\n",
    "        print(str(e))\n",
    "    except requests.RequestException as e:\n",
    "        print(\"OOPS!! General Error\")\n",
    "        print(str(e))\n",
    "\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "    # sender()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebc030f0",
   "metadata": {},
   "source": [
    "## Send this desktop's IP address to the HL2\n",
    "This enables the HL2 to send the gaze data correctly to the computer where this script is running.\n",
    "Make sure to enter your computer's IP-address and a free port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca36ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "def find_free_port():\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind(('', 0))  # 0 means to select an arbitrary unused port\n",
    "        return s.getsockname()[1]\n",
    "\n",
    "free_port = find_free_port()\n",
    "print(f\"Free port found: {free_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipaddress = \"10.2.2.152\"\n",
    "# ipaddress = \"localhost\"\n",
    "# ipaddress = \"130.82.27.178\"\n",
    "send_this_desktop_ip_to_holo(ipaddress, free_port)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9268036",
   "metadata": {},
   "source": [
    "## Run a simple Flask server that receives the raw gaze data from the HL2\n",
    "Make sure to enter your computer's IP-address and a suitable port in the last line. \\\n",
    "Note: `0.0.0.0` as IP address lets the server listen on all its IP addresses, usually 127.0.0.1 and the public IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d07b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_executor import Executor\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger('waitress')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "app = Flask(__name__)\n",
    "executor = Executor(app)\n",
    "\n",
    "@app.route('/', methods=['POST', 'PUT'])\n",
    "def result():\n",
    "    new_csv = request.files[\"gazedata\"].read()\n",
    "    filename = request.form[\"filename\"]\n",
    "    print(f\"filename: {filename}\")\n",
    "    filepath = os.path.join(\"./OnlineGazeDataChunks/\", filename)\n",
    "    print(f\"filepath: {filepath}\")\n",
    "    outF = open(filepath, \"wb\")\n",
    "    outF.write(new_csv)\n",
    "    executor.submit(start_feature_calculation,filepath)\n",
    "    return 'Received !'  \n",
    "\n",
    "# '''\n",
    "def start_feature_calculation(filepath):\n",
    "    print(\"start fc for: \", filepath)\n",
    "    if os.stat(filepath).st_size != 0:\n",
    "        print(f\"File {filepath} is not empty, start feature calculation\")\n",
    "        feature_file_path = csv_to_features(filepath)\n",
    "        if os.stat(feature_file_path).st_size != 0:\n",
    "            print(\"start prediction for: \", feature_file_path)\n",
    "            predict_class_for_last_chunk(feature_file_path)\n",
    "        else:\n",
    "            print(f\"File {feature_file_path} is empty!\")\n",
    "    else:\n",
    "        print(f\"File {filepath} is empty!\")\n",
    "# '''\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from waitress import serve\n",
    "    serve(app, listen=f\"0.0.0.0:{free_port}\")\n",
    "    # serve(app, listen=\"10.2.2.152:5555\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
